{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from pyepw.epw import EPW\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeToUTF(file):\n",
    "    BLOCKSIZE = 1048576 # or some other, desired size in bytes\n",
    "\n",
    "    second = file.split('/')\n",
    "    second.pop()\n",
    "    second = \"/\".join(second)\n",
    "    second += \"/example.epw\"\n",
    "\n",
    "    with codecs.open(file, \"r\", \"ISO-8859-1\") as sourceFile:\n",
    "        with codecs.open(second, \"w\", \"utf-8\") as targetFile:\n",
    "            while True:\n",
    "                contents = sourceFile.read(BLOCKSIZE)\n",
    "                if not contents:\n",
    "                    break\n",
    "                targetFile.write(contents.replace('ISO-8859-1','utf-8'))\n",
    "\n",
    "    os.rename(second,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCountryName(code):\n",
    "    country = pycountry.countries.get(alpha_3=code)\n",
    "    country_name = country.name\n",
    "    return country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJsonFile(epw, epwName):\n",
    "    json_file = {}\n",
    "\n",
    "    country = getCountryName(epw.location._country)\n",
    "\n",
    "    json_file['location'] = {\n",
    "        \"city\" : epw.location._city,\n",
    "        \"country\" : country,\n",
    "        \"adm03\" : epw.location._country,\n",
    "        \"wmo\" : int(epw.location._wmo),\n",
    "        \"lat\" : float(epw.location._latitude),\n",
    "        \"long\" : float(epw.location._longitude),\n",
    "        \"alt\" : float(epw.location._elevation),\n",
    "        \"epwName\" : epwName\n",
    "    }\n",
    "\n",
    "\n",
    "    json_file['typical_extremePeriods'] = []\n",
    "    [json_file['typical_extremePeriods'].append({\n",
    "        \"typeOfPeriod\" : str(period).split(',')[2],\n",
    "        \"firstDate\" : str(period).split(',')[3].replace(\" \",\"\"),\n",
    "        \"lastDate\" : str(period).split(',')[4].replace(\" \",\"\"),\n",
    "        \"season\" : str(period).split(',')[1].split('-')[0].replace(\" \",\"\"),\n",
    "        \"city\" : epw.location._city,\n",
    "        \"adm03\" : epw.location._country,\n",
    "        \"wmo\" : int(epw.location._wmo),\n",
    "        \"epwName\" : epwName\n",
    "    }) for period in epw.typical_or_extreme_periods._typical_or_extreme_periods]\n",
    "\n",
    "    resInt = len(str(epw.ground_temperatures).split(\",\")[2:])/16\n",
    "\n",
    "\n",
    "    temps = chunkIt(str(epw.ground_temperatures).split(\",\")[2:],resInt)\n",
    "\n",
    "    json_file['groundTemperatures'] = [] \n",
    "    [json_file['groundTemperatures'].append({\n",
    "        \"groundTemperatureDepth\" : elem[0],\n",
    "        \"groundConductivity\" : elem[1],\n",
    "        \"groundDensity\" : elem[2],\n",
    "        \"groundSpecificHeat\" : elem[3],\n",
    "        \"january\" : elem[4],\n",
    "        \"february\" : elem[5],\n",
    "        \"march\" : elem[6],\n",
    "        \"april\" : elem[7],\n",
    "        \"may\" : elem[8],\n",
    "        \"june\" : elem[9],\n",
    "        \"july\" : elem[10],\n",
    "        \"august\" : elem[11],\n",
    "        \"september\" : elem[12],\n",
    "        \"october\" : elem[13],\n",
    "        \"november\" : elem[14],\n",
    "        \"december\" : elem[15],\n",
    "        \"city\" : epw.location._city,\n",
    "        \"adm03\" : epw.location._country,\n",
    "        \"wmo\" : int(epw.location._wmo),\n",
    "        \"epwName\" : epwName\n",
    "    }) for elem in temps]\n",
    "\n",
    "    json_file['epw'] = []\n",
    "    [json_file['epw'].append({\n",
    "        \"Year\": data._year,\n",
    "        \"Month\": data._month,\n",
    "        \"Day\": data._day,\n",
    "        \"Hour\": data._hour,\n",
    "        \"DryBulbTemperature\": data._dry_bulb_temperature,\n",
    "        \"DewPointTemperature\": data._dew_point_temperature,\n",
    "        \"RelativeHumidity\": data._relative_humidity,\n",
    "        \"AtmosphericStationPressure\": data._atmospheric_station_pressure,\n",
    "        \"ExtraterrestrialHorizontalRadiation\": data._extraterrestrial_horizontal_radiation,\n",
    "        \"ExtraterrestrialDirectNormalRadiation\": data._extraterrestrial_direct_normal_radiation,\n",
    "        \"HorizontalInfraredRadiationIntensity\": data._horizontal_infrared_radiation_intensity,\n",
    "        \"GlobalHorizontalRadiation\": data._global_horizontal_radiation,\n",
    "        \"DirectNormalRadiation\": data._direct_normal_radiation,\n",
    "        \"DiffuseHorizontalRadiation\": data._diffuse_horizontal_radiation,\n",
    "        \"GlobalHorizontalIlluminance\": data._global_horizontal_illuminance,\n",
    "        \"DirectNormalIlluminance\": data._direct_normal_illuminance,\n",
    "        \"DiffuseHorizontalIlluminance\": data._diffuse_horizontal_illuminance,\n",
    "        \"ZenithLuminance\": data._zenith_luminance,\n",
    "        \"WindDirection\": data._wind_direction,\n",
    "        \"WindSpeed\": data._wind_speed,\n",
    "        \"TotalSkyCover\": data._total_sky_cover,\n",
    "        \"OpaqueSkyCover\": data._opaque_sky_cover,\n",
    "        \"Visibility\": data._visibility,\n",
    "        \"CeilingHeight\": data._ceiling_height,\n",
    "        \"PrecipitableWater\": data._precipitable_water,\n",
    "        \"AerosolOpticalDepth\": data._aerosol_optical_depth,\n",
    "        \"SnowDepth\": data._snow_depth,\n",
    "        \"DaysSinceLastSnowfall\": data._days_since_last_snowfall,\n",
    "        \"Albedo\": data._albedo,\n",
    "        \"LiquidPrecipitationDepth\": data._liquid_precipitation_depth,\n",
    "        \"LiquidPrecipitationQuantity\": data._liquid_precipitation_quantity,\n",
    "        \"city\" : epw.location._city,\n",
    "        \"adm03\" : epw.location._country,\n",
    "        \"wmo\" : int(epw.location._wmo),\n",
    "        \"epwName\" : epwName \n",
    "    }) for data in epw.weatherdata]\n",
    "\n",
    "\n",
    "\n",
    "    return json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "epw = EPW()\n",
    "\n",
    "epwName = \"ESP_Madrid.082210_IWEC.epw\"\n",
    "\n",
    "encodeToUTF(\"Example/ESP_Madrid.082210_IWEC.epw\")\n",
    "\n",
    "epw.read(r\"Example/ESP_Madrid.082210_IWEC.epw\")\n",
    "\n",
    "\n",
    "json_file = createJsonFile(epw, epwName)\n",
    "\n",
    "document = open(\"Example/\" + epwName + \".json\", \"a+\")\n",
    "json.dump(json_file, document, indent=4)\n",
    "document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}